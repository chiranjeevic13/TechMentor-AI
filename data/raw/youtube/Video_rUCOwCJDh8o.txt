Source: https://www.youtube.com/watch?v=rUCOwCJDh8o
Channel: Fireship

Last week, somebody pushed some bad code into production and it broke a large chunk of the internet. The Snapchat, Spotify, and Discord all started spurring out while Cloudflare's workers KV service was also hit, which resulted in nearly 100% error rates for over 2 hours and created a domino effect that took down websites and services across the internet. The person to blame for this bad code is none other than Google Cloud Platform, which rents out the servers to many of your favorite apps. They have deeply apologized for the screw-up, but it just goes to show how much power Big Cloud has over the internet infrastructure that we take for granted. In today's video, we'll find out exactly how this massive outage happened from a software engineering perspective. It is June 16th, 2025, and you're watching the Code Report. Google Cloud not only broke the internet, but it also broke itself. Gmail, Google Calendar, Drive, Meet, and many other services went down. An outage of this magnitude can cost companies millions upon millions of dollars. But when you rent out servers on any big cloud provider, they provide you with a contract called a service level agreement. And it typically guarantees monthly uptime of 99.99% or greater. When things go down this bad, the cloud provider is in violation of this contract and you may be entitled to financial compensation in the form of SLA credits, which is basically Google refunding these companies for sucking at its job. That might cost Google a few million, but this outage does far more damage to their reputation as a cloud provider. In terms of market share, Google has been in third place for years behind Azure and AWS. And this recent incident is not going to do them any favors. But how did the disaster actually happen from a programming perspective? Well, Sundar recently said that AI is now writing well over 30% of Google's code. And so many people immediately jump to blame Gemini, but I can neither confirm nor deny that this was yet another Vive coding fail. It's more likely that this code was written by a human hand because it controls an extremely important part of Google Cloud. Basically, when customers make API requests to Google Cloud, they get routed to an API management service that verifies that the API request is authorized. This service also contains a data store to read quota and policy informations that can be replicated very quickly around the world. The service itself is deployed regionally and Google currently has data centers in 42 regions across the flat stationary plane we live upon. Normally everything works great, but back on May 29th, 2025, an additional quota policy check was added, which was supposed to be a new feature, but turned into a massive bug. The code path for this feature was never actually executed because it required a policy change that would trigger the code, but apparently that trigger was never pulled during the staging phase, so it looked like everything was all good. That sounds a lot like the CrowdStrike disaster last year. And in this case, the code path didn't have proper error handling, which would result in a null pointer that would cause the binary to crash. I was just talking about bad code with null pointers in my C video last week, but in any case, the bug lay there dormant until June 12th when a policy change was inserted, then replicated globally within seconds, and that caused the API management binary to go into a crash loop, leading to mass panic and chaos in the tech world. Luckily, Google developers did install a big red button to roll things back, but it took about 40 minutes to get that roll back started and about 4 hours to fully stabilize back to normal. It was a day that will live in infamy, but you can start building better products today thanks to this video sponsor, Postthog. You probably know Post Hog as an all-in-one platform for building better products. What you probably don't know is that Post Hog just changed the game again with the release of Max, their AI powered product analyst and assistant that lives directly inside your Post Hog app. It's deeply connected to your data, which allows you to do all sorts of cool things like research answers, ask product questions with natural language, generate data visualizations, get stuff done on your behalf in the Post Hog UI, and answer questions about the documentation. And that's combined with everything else Post Hog has to offer like analytics, feature flags, session replays, and much, much more. Give Post Hog a shot today with the link below. This has been the code report. Thanks for watching and I will see you in the next 