Source: https://www.youtube.com/watch?v=6fnmXX8RK0s
Channel: Fireship

Anyone who has ever graduated from kindergarten should know the seven foundational data structures of computer science, which include arrays, link list, hashts, stacks, cues, graphs, and trees. But if you didn't graduate from kindergarten, here's a quick crash course. A data structure is just a way to organize data in a computer so you can do CRUD to it efficiently. Create, read, update, and delete it. An array is like a row of numbered cubbies. A linked list is like a treasure map of clues. A hash table is like a locker with your name on it. A stack is like a stack of books. A Q is like a line of kids at the cafeteria. A graph is a spiderweb. And a tree is well like a tree. The programming is all about solving problems. I've got 99 problems, but a data structure ain't one. But for some programmers, data structures do become a problem. And in today's video, we'll look at a few unusual situations where these simple data structures were not good enough or smart enough to get the job done. Let's start by talking about the B tree, not to be confused with a binary tree. One of the most exhilarating things that ever happened in my life was the first time I implemented a binary search tree, which prevented my algorithm's time complexity from going burr, turning O of N squared into a much faster O of login. But binary search trees have one problem. Each node in the tree can only have two children, which means the depth of the tree grows rapidly and doesn't scale very well for things like modern hard drives with massive amounts of data to search through. To address this problem, a long time ago, programmers at Boeing developed the self-balancing tree or B tree. Although nowadays, you'll mostly find B+ trees in file systems and databases. At a high level, what makes them special is that each node can have multiple children of sorted keys. These are called internal nodes, and they work like signposts that point to leaf nodes that hold the actual data or pointers to data. So, it works kind of like a binary tree, but greatly reduces the dis IO operations by cutting down the height of the tree. Pretty cool. But there are many other types of trees in nature and in computers like the radex tree. Like there are billions of IP addresses in the world. But have you ever wondered how computers route between them so efficiently to make the internet work? A radix tree is special because nodes with only one child are merged with their parent and that makes them highly efficient when finding values with a shared prefix like an IP address. For example, if I made a tree to find words that start with C, our tree might look like this. But in a radics tree, we can reduce the depth by merging the last child. That's ideal when you have many shared prefixes, but doesn't work so well with big complex strings like all the vibecoded slop you're trying to debug in your IDE right now. A rope is yet another type of tree that breaks down strings into manageable chunks. Instead of one continuous strand, you cut it into many smaller, manageable segments. Then you tie these segments together using smaller knots that also tell you how long each segment they represent is. This allows tools like text editors to more efficiently modify large documents. But in some cases, figuring out what not to search is more important, and that's where Bloom filters come in. It's a probabilistic data structure that can tell you if an item is definitely not in a set or maybe is in a set. It works by using multiple hash functions to set and check bits in a fixed-sized array, allowing fast membership tests with possible false positives, but no false negatives. It's like a bouncer at a club who always knows exactly who to kick out. One of the weirdest things in nature, though, is the cuckoo bird. A bird that sneaks into another bird's nest and replaces its eggs with its own, tricking the host to incubate and care for the cuckoo chick. This behavior not only inspired the term cuckled, but also cuckoo hashing and programming. According to my wife's boyfriend, it's a collision resolution technique where each key in a hash table has two or more possible positions. And if one spot is taken, the existing key is kicked out like a cuckoo and reinserted in an alternate location. The end result is constant time worst case complexity for lookups, which is as fast as you can possibly go when it comes to algorithms. But if you want to optimize your own code with these weird data structures, you need to know about Code Rabbit, the sponsor of today's video. They just released a new VS Code extension that gives you advanced code reviews right in your editor, so you can catch the majority of bugs before you even submit a pull request. Unlike other tools, the extension understands the context of your entire codebase, allowing it to catch more bugs, like all the AI slop your favorite codegen tool left behind. It gives you lineby-line comments on all issues, so you can see it reasoning. Then, it offers simple one-click fixes to help you clean things up quickly. The Code Rabbit is free to use in the IDE and works seamlessly with VS Code as well as forks like Cursor and Windsurf. Download the extension using the link below to try it out. Thanks for watching and I will see you in the next 